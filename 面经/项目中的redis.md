# redis在项目中的应用
为什么要使用缓存？
针对读多写少的场景，缓存可以减少数据库的访问次数，提高系统的性能

如果是读少写多的场景，直接使用数据库即可

## 1. 缓存
将用户信息、ip uv（HyperLogLog）、短链接跳转映射关系缓存到redis中

HyperLogLog是基于string实现的，单个HLL的大小不超过16KB，误差在0.81%以内，适用于对大数据量的去重统计
HLL支持合并数据，从而得到连续几天的uv pv数据

下面是黑马点评的HLL使用案例：
![img_4.png](img_4.png)
经过测试，添加了100万条不重复数据，HLL的内存占用才14KB

本项目是将用户信息存储在JWT Token中还是存储在Redis中？

JWT 方案的优点是无状态，每个请求都包含了所有需要的信息，服务器不需要存储会话信息。这使得这种方案非常适合于分布式微服务架构。

但是，这种方案的缺点是如果用户信息很大，每次请求都需要传输大量的数据。此外，一旦JWT Token被颁发，就无法从服务器端撤销，除非Token过期。

总结

如果你的应用需要处理大量的用户信息，并且需要能够管理会话状态（例如，登出用户或者使会话过期），那么将用户信息存储在Redis中可能是一个更好的选择。

如果你的应用是一个分布式微服务架构，并且每个请求的用户信息不是很大，那么使用JWT Token可能是一个更好的选择。

在你的项目中，你已经选择了将用户信息存储在Redis中，并且在`TokenValidateGatewayFilterFactory.java`文件中，你已经实现了从Redis中获取用户信息的逻辑。

### 可能会问的问题：
缓存穿透、缓存击穿、缓存雪崩的解决方案

### 缓存穿透：
定义：缓存穿透是指请求查询一定不存在的数据，mysql查询不到数据，缓存中也没有，导致大量请求访问数据库，造成数据库压力过大

解决方案：

1.缓存空对象
![img.png](imgx.png)

2.布隆过滤器
![img_1.png](img_1.png)

本项目中短链接跳转模块同时使用了上述两种技术，即当用户访问一个不存在的短链接时，会先查询一下布隆过滤器，如果布隆过滤器中不存在，则直接返回，不再查询数据库。
如果布隆过滤器显示存在，则再查询一下缓存，如果缓存中存在，则直接返回，如果缓存中不存在，则查询是否有缓存空对象，如果没有，最后才查询数据库，查询到数据后，将数据存入缓存中，同时更新布隆过滤器

使用布隆过滤器判断短链接的存在性的方案比直接使用缓存空对象的方案性能更好，
因为布隆过滤器可以用极少的空间来存储大量的数据，而缓存空对象需要占用大量的内存空间
但是某些情况下布隆过滤器会误判，也就是把不存在误判为存在，为了防止有人恶意利用这个漏洞进行攻击，还需要对这些误判的短链接缓存空对象

如果短链接在布隆过滤器中显示存在，且没有查询到缓存空对象，再查询数据库，查询到数据后，将数据存入缓存中，同时更新布隆过滤器，如果数据库中没有，则缓存一个空对象。

查询数据库时，使用了双检锁搭配布隆过滤器的方案，保证了并发安全，并减少了数据库的访问次数

### 缓存击穿：
定义：也叫热点Key问题，项目中某个热key突然失效，此时有大量的并发请求过来，这些并发的请求可能会瞬间把DB压垮

解决方案：
1.分布式锁 + 双重判定
只允许一个线程去查询数据库，其他线程等待

2.逻辑过期
给热Key设置一个逻辑过期字段
![img_2.png](img_2.png)
为什么是设置逻辑过期字段而不是直接设置过期时间？
因为我们这里为了保证服务的可用性牺牲了数据的实时性，如果直接设置过期时间，可能会出现热key失效后，大量请求直接打到数据库上的情况

本项目中的短链接跳转模块用到了分布式锁 + 双重判定的方案，保证了并发安全，减少了数据库的访问次数，具体见缓存穿透的解决方案，这里不再赘述

### 缓存雪崩：
定义：缓存雪崩是指在某一个时间段，**缓存集中过期失效或redis宕机**，导致大量的请求直接打到数据库上，造成数据库短时间内承受大量请求

产生原因：
1.大量缓存集中在某一个时间段过期
2.缓存服务器宕机

解决方案：
1.缓存数据的过期时间设置随机，防止同一时间大量数据过期
2.利用Redis集群提高服务的可用性哨兵模式、集群模式
3.给系统设计多级缓存，如本地缓存、分布式缓存、数据库缓存
4.给系统添加限流降级机制，这是最后的保障，适用于缓存雪崩、缓存击穿、缓存穿透

你们的项目有没有为缓存雪崩做准备？
我们设置了一主一从搭配一个哨兵节点的架构，保证了redis的高可用性，防止了缓存雪崩的发生

### 总结
![img_3.png](img_3.png)

## 2. 布隆过滤器
在创建短链接的模块中布隆过滤器搭配数据库唯一索引使用，实现短链接去重。
在跳转短链接的模块中布隆过滤器搭配缓存空对象使用，实现短链接的存在性判断。

### 布隆过滤器在项目中的应用

1、如果当前的短链接是没用过的，但是被误判用过了，那也没事，直接会被跳过，继续生成

2、如果当前的短链接是用过的，但是在多线程情况下，Bloom过滤器中还没来得及添加该短链接，但该短链接已经入库成功了，被误判说没有用过，那么在插入到数据库的时候，就会被数据库的唯一字段，短链接拦截，出现异常

3、如果在数据库没有拦截，说明没有误判, 获取到的就是没用过的，正常进行，不抛异常

## 3. 分布式锁
分布式锁的实现方式有很多，比如zookeeper、redis等，本项目中使用了redis实现分布式锁

如何使用redis实现分布式锁？

1.使用setnx命令，如果返回1，则表示获取锁成功，否则获取锁失败

2.设置锁的过期时间，防止死锁

3.使用lua脚本，保证原子性，具体是指将setnx和设置过期时间的两个操作合并成一个操作

为什么要使用分布式锁？普通的锁不行吗？
分布式锁是为了解决分布式环境下的并发问题，普通的锁只能解决单机并发问题.

Redis实现分布式锁如何合理的控制锁的有效时长?
1.根据业务场景来估计，不准确，所以这个方案是不可取的
2.单独开一个线程给锁续期，如果时间要到了，但我们的业务还没执行完，就给锁续期，这样可以保证锁的有效时长。

redission帮我们实现了方案2，它有一个看门狗机制，会定时给锁续期，保证锁的有效时长

下面是redission分布式锁的执行流程：
![img_18.png](img_18.png)
注意：redission底层加锁及给锁设置过期时间是通过lua脚本实现的，保证了原子性

我们自己使用setnx命令设置的分布式锁和redission的分布式锁有什么区别？
1.我们自己使用setnx命令设置的分布式锁是不可重入的，redission的分布式锁是可重入的
2.redission的分布式锁有看门狗机制，保证了锁的有效时长，我们自己设置的分布式锁没有看门狗机制，需要自己维护锁的有效时长
![img_19.png](img_19.png)
3.redission中有红锁，RedLock（redis distributed lock的缩写），RedLock的优点是它可以在分布式环境中实现互斥锁，而且即使有一部分 Redis 实例出现问题，也不会影响锁的功能。但是，RedLock 算法也有一些缺点，比如它需要在多个 Redis 实例上操作，可能会导致性能问题，而且如果 Redis 实例的数量不够多，可能会影响锁的可靠性。

如何正确介绍分布式锁，要结合我们的项目来回答：
![img_20.png](img_20.png)
我们项目里面使用了Redission分布式读写锁来保证在短链接修改时能正确将用户访问记录存入对应的表中，具体做法是，在修改短链接分组id的时候添加写锁，消息队列下游同步用户信息到数据库时，要添加读锁，保证数据的一致性。

如果面试官对项目业务感兴趣，可能会问我们的项目中为什么要添加读写锁，为什么要添加写锁，为什么要添加读锁，这时我们就要结合我们的项目来回答。
为什么修改用户分组id要添加写锁？同时消息队列下游同步用户信息到数据库时要添加读锁？
因为短链接信息表是以gid来分片的，修改短链接分组id时，要将原记录删除，然后将新记录插入，这个过程是一个写操作，需要添加写锁。
而消息队列下游同步用户信息到数据库时，不仅仅要把用户访问信息（浏览器，操作系统，设备，地区，网络）同步到对应的表中，还要更新短链接表中对应短链接的历史总uv和pv，需要添加读锁。
如果不添加读写锁，可能会出现用户访问记录不能正确统计的情况，比如我现在有个线程在修改短链接，已经将原短链接删除了，但更新后的短链接还没插入，这时另一个线程来了，要将用户访问记录同步到数据库，这时就会出现数据不一致的情况

## 4. 消息幂等器 (消息去重)
下游服务处理消息时，记录消息id，如果消息id已经存在，则不处理，避免重复处理消息。

消息幂等主要是通过redis的setnx命令来实现的，如果返回1，则表示消息id不存在，可以处理消息，否则不处理消息

除此之外，我们还为每个消息设置了一个处理完成的标记，如果判断该消息没有被处理过，则处理消息，处理完消息后，将消息处理完成的标记设置为1

为什么要设置这样一个处理完成的标记？

其实是因为要考虑到生产上的一些极端情况，比如消费线程（消息队列下游）突然断电了，那么就会导致消息既没有处理完成也没有抛出异常的情况。

一般消息处理完后（onMessage方法执行结束后）会返回给消息队列一个ACK，表示消息已经处理完成，但是如果消费线程突然断电了，

那么就会导致消息队列认为消息没有处理完成，上游会再次将消息发送给消费线程，这时就会出现消息重复处理的情况，并且针对这种情况，我们要抛出异常，让消息队列重试

## 5. 限流 （缓存用户名，并利用Inc命令，每次请求都加1，超过限流阈值则拒绝请求）
在过滤器那里设置了限流窗口，如果超过限流阈值，则直接返回，不再继续执行后续逻辑


# redis和mysql如何保持数据一致性？
1.是删除缓存还是更新缓存？
对于redis缓存，我们一般采用删除替代更新的策略，这样可以减少无用的更新操作，提高性能
![img_5.png](img_5.png)
2.如何保证缓存和数据库同时更新成功和失败？
添加事务
3.是先删除缓存还是先更新数据库？
![img_7.png](img_7.png)
如果先删除缓存，再更新数据库，如果重建流程过长，可能会出现数据不一致的情况。
如果先更新数据库，再删除缓存，也有可能出现数据不一致的情况，但出现上图所示情况的概率更低。
4.延迟双删策略：
![img_8.png](img_8.png)

# redis持久化
1.RDB（Redis Database Backup）

RDB是Redis默认的持久化方式，分为人工命令和自动触发两种方式

人工命令：save、bgsave
其中save是阻塞的，会阻塞redis的主线程，bgsave是非阻塞的，会fork一个子进程来执行持久化操作

自动触发：在redis.conf中配置save参数，当满足条件时，自动触发持久化操作
![img_9.png](img_9.png)

2.AOF（Append Only File）
AOF默认是关闭的，需要手动开启
AOF的命令记录频率可以通过appendfsync参数来配置
![img_10.png](img_10.png)
一般是采用每秒刷盘的策略

AOF可能会记录大量的写操作，但我们只需要最后一次的写操作，所以可以通过BGREWRITEAOF命令来重写AOF文件，减少AOF文件的大小

3.RDB和AOF的比较
![img_11.png](img_11.png)
RDB文件小是因为它是二进制文件，而且经过了压缩，而AOF文件是文本文件，所以比较大

# redis的数据据过期策略
分为惰性删除和定期删除
惰性删除：当用户访问一个key时，如果发现该key已经过期，则删除该key
![img_12.png](img_12.png)
定期删除：每隔一段时间，redis会随机抽取一些key，检查是否过期，如果过期则删除
![img_13.png](img_13.png)

# redis的数据淘汰策略
数据过期策略是指某些设置了过期的key的删除策略，而数据淘汰策略是指内存满了之后，redis如何选择哪些key删除的策略
下面是常见的数据淘汰策略：
![img_14.png](img_14.png)
只需要记住怎么描述LRU和LFU的策略即可
![img_15.png](img_15.png)

面试常见问题：
![img_16.png](img_16.png)

![img_17.png](img_17.png)

# redis集群相关问题
## 主从数据同步原理
### 全量同步：从节点是第一次连接主节点时，主节点会将所有数据发送给从节点
具体过程是，主节点会fork一个子进程，将数据写入到rdb文件中，然后将rdb文件发送给从节点，从节点接收到rdb文件后，将rdb文件写入到内存中

![img_21.png](img_21.png)

在同步时，如果主节点有数据写入，主节点会生成一个增量日志文件用来记录从节点同步期内的增量数据，从节点同步完主节点发送的rdb文件后，主节点将增量文件发送给从节点，

从节点继续同步增量文件，直到同步完所有增量文件


### 增量同步：主节点会将增量数据发送给从节点
如果从节点发现与主节点的repliId一致，但offset不一致，说明从节点的数据不是最新的，此时主节点会将增量数据发送给从节点，从节点接收到增量数据后，将增量数据写入到内存中
![img_22.png](img_22.png)

总结：
![img_23.png](img_23.png)

## 哨兵机制
![img_24.png](img_24.png)

![img_25.png](img_25.png)

常见问题：脑裂问题

![img_26.png](img_26.png)

如果哨兵节点、redis主节点、从节点处于不同的网络分区，万一哨兵节点和当前检测的redis集群的主节点断开连接，哨兵节点会选举出一个新的主节点，而客户端和当前主节点还保持连接，这时就会出现脑裂问题，因为客户端还在与旧的主节点通信，这时就会出现数据不一致的情况

当网络分区故障恢复后，原来的主节点会变成slave节点，要与新的主节点同步数据（原主节点会清空自己的数据，再进行数据同步)，在断开连接的时间内客户端写入的数据会丢失

解决脑裂的方案：
1.设置redis.conf中的min-slaves-to-write参数为 1，当没有从节点时，主节点不会接受写操作

2.设置redis.conf中的主从同步延迟参数，超过一定延迟的，拒绝客户端写操作

面试提问：
![img_27.png](img_27.png)

![img_28.png](img_28.png)

主从复制解决：高并发读的问题；哨兵模式解决高可用问题

多个slave可以解决高并发读的问题，多个master可以解决高并发写的问题

集群既可以解决高并发写的问题，又可以解决高并发读的问题

## 分片集群
![img_29.png](img_29.png)  

为什么redis集群的哈希槽采用16384个槽？

如果哈希槽的数量过少，可能会导致数据分布不均

如果哈希槽的数量过多，可能会导致内存占用过高

![img_30.png](img_30.png)

# redis的其他相关问题
![img_31.png](img_31.png)

![img_32.png](img_32.png)

![img_33.png](img_33.png)

![img_34.png](img_34.png)

![img_35.png](img_35.png)

多路复用相比于前面两种方式的优点是，它可以同时处理多个客户端的请求，并且不是排队处理，而是并发处理，提高了redis的性能

![img_36.png](img_36.png)

就类似于客户点餐，select和poll方式相当于餐台有个灯泡，服务员看到灯泡亮了（菜做好了），就去处理，遍历所有客户，问是谁点的菜，然后给他上菜

而epoll方式相当于扫码点餐，菜做好了的同时，服务员就知道是谁点的菜，直接给他上菜，不用遍历所有客户

![img_37.png](img_37.png)

![img_38.png](img_38.png)



